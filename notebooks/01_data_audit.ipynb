{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 \u2014 Data Audit (Goldenhar-CFID)\n",
        "\n",
        "**Objective**: Verify dataset integrity before training.\n",
        "\n",
        "This notebook checks:\n",
        "- directory structure (`images/`, `labels/`)\n",
        "- image\u2013label pairing\n",
        "- class distribution (counts, imbalance)\n",
        "- label sanity: normalized boxes, range checks, empty labels\n",
        "- split leakage checks (train/val overlap)\n",
        "\n",
        "**Outputs**:\n",
        "- `outputs/tables/data_audit_summary.csv`\n",
        "- `outputs/figures/data_class_distribution.png`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "\n",
        "DATA_ROOT = Path(os.getenv(\"DATA_ROOT\", \"../data\"))\n",
        "OUTPUT_ROOT = Path(os.getenv(\"OUTPUT_ROOT\", \"../outputs\"))\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "(OUTPUT_ROOT / \"tables\").mkdir(parents=True, exist_ok=True)\n",
        "(OUTPUT_ROOT / \"figures\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DATASET_ROOT = DATA_ROOT / \"processed\" / \"D1_yolo640\"  # change to D2_balanced_yolo640 if needed\n",
        "IMAGES_DIR = DATASET_ROOT / \"images\"\n",
        "LABELS_DIR = DATASET_ROOT / \"labels\"\n",
        "\n",
        "CLASSES = [\n",
        "    \"Cleft Lip\",\n",
        "    \"Epibulbar Dermoid\",\n",
        "    \"Eyelid Coloboma\",\n",
        "    \"Facial Asymmetry\",\n",
        "    \"Malocclusion\",\n",
        "    \"Microtia\",\n",
        "    \"Vertebral Abnormalities\",\n",
        "]\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "def read_yaml(p: Path):\n",
        "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def list_images(images_dir: Path):\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "    return sorted([p for p in images_dir.rglob(\"*\") if p.suffix.lower() in exts])\n",
        "\n",
        "def label_path_for_image(img_path: Path, labels_dir: Path):\n",
        "    return labels_dir / (img_path.stem + \".txt\")\n",
        "\n",
        "def parse_yolo_label_file(p: Path):\n",
        "    if not p.exists():\n",
        "        return []\n",
        "    txt = p.read_text(encoding=\"utf-8\").strip()\n",
        "    if not txt:\n",
        "        return []\n",
        "    rows = []\n",
        "    for line in txt.splitlines():\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) != 5:\n",
        "            continue\n",
        "        c, x, y, w, h = parts\n",
        "        rows.append((int(float(c)), float(x), float(y), float(w), float(h)))\n",
        "    return rows\n",
        "\n",
        "print(\"DATASET_ROOT:\", DATASET_ROOT)\n",
        "print(\"IMAGES_DIR exists:\", IMAGES_DIR.exists())\n",
        "print(\"LABELS_DIR exists:\", LABELS_DIR.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = list_images(IMAGES_DIR)\n",
        "print(\"#images:\", len(images))\n",
        "\n",
        "missing_labels = 0\n",
        "empty_labels = 0\n",
        "bad_rows = 0\n",
        "\n",
        "class_counts = np.zeros(NUM_CLASSES, dtype=int)\n",
        "bbox_out_of_range = 0\n",
        "bbox_negative = 0\n",
        "\n",
        "records = []\n",
        "for img in images:\n",
        "    lp = label_path_for_image(img, LABELS_DIR)\n",
        "    if not lp.exists():\n",
        "        missing_labels += 1\n",
        "        continue\n",
        "    ann = parse_yolo_label_file(lp)\n",
        "    if len(ann) == 0:\n",
        "        empty_labels += 1\n",
        "    for (c, x, y, w, h) in ann:\n",
        "        if c < 0 or c >= NUM_CLASSES:\n",
        "            bad_rows += 1\n",
        "            continue\n",
        "        class_counts[c] += 1\n",
        "        if min(x, y, w, h) < 0:\n",
        "            bbox_negative += 1\n",
        "        if max(x, y, w, h) > 1.0:\n",
        "            bbox_out_of_range += 1\n",
        "    records.append({\n",
        "        \"image\": str(img.relative_to(DATASET_ROOT)),\n",
        "        \"label\": str(lp.relative_to(DATASET_ROOT)),\n",
        "        \"n_boxes\": len(ann),\n",
        "    })\n",
        "\n",
        "audit = {\n",
        "    \"n_images\": len(images),\n",
        "    \"missing_label_files\": int(missing_labels),\n",
        "    \"empty_label_files\": int(empty_labels),\n",
        "    \"bad_label_rows\": int(bad_rows),\n",
        "    \"bbox_negative_values\": int(bbox_negative),\n",
        "    \"bbox_out_of_range\": int(bbox_out_of_range),\n",
        "}\n",
        "\n",
        "audit_df = pd.DataFrame([audit])\n",
        "audit_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_csv = OUTPUT_ROOT / \"tables\" / \"data_audit_summary.csv\"\n",
        "audit_df.to_csv(out_csv, index=False)\n",
        "print(\"Saved:\", out_csv)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 4), dpi=200)\n",
        "plt.bar(np.arange(NUM_CLASSES), class_counts)\n",
        "plt.xticks(np.arange(NUM_CLASSES), CLASSES, rotation=30, ha=\"right\")\n",
        "plt.ylabel(\"#Boxes\")\n",
        "plt.title(\"Class Distribution (YOLO labels)\")\n",
        "plt.tight_layout()\n",
        "out_fig = OUTPUT_ROOT / \"figures\" / \"data_class_distribution.png\"\n",
        "plt.savefig(out_fig, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Saved:\", out_fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split leakage check\n",
        "\n",
        "This checks that **train_images** and **val_images** are disjoint for each split manifest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SPLITS_ROOT = DATA_ROOT / \"splits\"\n",
        "\n",
        "def leakage_check(manifest_path: Path):\n",
        "    m = read_yaml(manifest_path)\n",
        "    tr = set(m.get(\"train_images\", []))\n",
        "    va = set(m.get(\"val_images\", []))\n",
        "    overlap = tr.intersection(va)\n",
        "    return {\n",
        "        \"manifest\": str(manifest_path),\n",
        "        \"n_train\": len(tr),\n",
        "        \"n_val\": len(va),\n",
        "        \"overlap\": len(overlap),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for p in sorted(SPLITS_ROOT.rglob(\"run*_seed*.yaml\")):\n",
        "    rows.append(leakage_check(p))\n",
        "\n",
        "leak_df = pd.DataFrame(rows)\n",
        "leak_df.sort_values([\"overlap\", \"manifest\"], ascending=[False, True]).head(20)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}