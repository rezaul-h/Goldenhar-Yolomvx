experiment:
  model_name: detr
  img_size: 640
  epochs: 100
  batch_size: 8
  workers: 8
  device: auto
  amp: true
  deterministic: true

optimization:
  optimizer: adamw
  lr_backbone: 0.00001
  lr_transformer: 0.0001
  weight_decay: 0.0001
  warmup_epochs: 5
  gradient_clip_norm: 0.1

scheduler:
  name: step
  step_size: 50
  gamma: 0.1

loss:
  matcher_cost:
    class: 1.0
    bbox: 5.0
    giou: 2.0
  weights:
    class: 1.0
    bbox: 5.0
    giou: 2.0
  eos_coef: 0.1

logging:
  save_dir: outputs
  project: goldenhar-transformers